{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))))\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meval_NN\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_eval_save_NN\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sys\n",
    "import os\n",
    "# sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))))\n",
    "from eval_NN import train_eval_save_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# TRAIN_CSV = \"data/processed/cleaned_data.csv\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# MODEL_PATH = \"models/trained/NN_model.pkl\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m BASE_DIR\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(os\u001b[38;5;241m.\u001b[39mgetcwd())))\n\u001b[0;32m      4\u001b[0m csv_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(BASE_DIR,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocessed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcleaned_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m outputPath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(BASE_DIR,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrained\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNN_model.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# TRAIN_CSV = \"data/processed/cleaned_data.csv\"\n",
    "# MODEL_PATH = \"models/trained/NN_model.pkl\"\n",
    "BASE_DIR=os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd())))\n",
    "csv_path = os.path.join(BASE_DIR,\"data\", \"processed\", \"cleaned_data.csv\")\n",
    "outputPath = os.path.join(BASE_DIR,\"models\", \"trained\", \"NN_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "        'store_sales(in millions)', 'store_cost(in millions)', 'total_children',\n",
    "        'avg_cars_at home(approx)', 'num_children_at_home', 'gross_weight',\n",
    "        'net_weight', 'store_sqft', 'grocery_sqft', 'units_per_case', 'SRP'\n",
    "    ]\n",
    "target = 'cost'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[features].values\n",
    "data_output = df[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "data = scaler_X.fit_transform(data)\n",
    "data_output = scaler_y.fit_transform(data_output.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(data, dtype=torch.float32).to(device)\n",
    "data_output = torch.tensor(data_output, dtype=torch.float32).to(device).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "  Epoch [10/50] - Loss: 0.96918\n",
      "  Epoch [20/50] - Loss: 0.95668\n",
      "  Epoch [30/50] - Loss: 0.94333\n",
      "  Epoch [40/50] - Loss: 0.93374\n",
      "  Epoch [50/50] - Loss: 0.92632\n",
      "  Accuracy: 0.00000\n",
      "  Validation MSE: 894.61707\n",
      "  R² Score: 0.00986\n",
      "Fold 2/5\n",
      "  Epoch [10/50] - Loss: 0.96762\n",
      "  Epoch [20/50] - Loss: 0.95408\n",
      "  Epoch [30/50] - Loss: 0.94293\n",
      "  Epoch [40/50] - Loss: 0.93316\n",
      "  Epoch [50/50] - Loss: 0.92311\n",
      "  Accuracy: 0.00000\n",
      "  Validation MSE: 910.96362\n",
      "  R² Score: -0.00085\n",
      "Fold 3/5\n",
      "  Epoch [10/50] - Loss: 0.97066\n",
      "  Epoch [20/50] - Loss: 0.95641\n",
      "  Epoch [30/50] - Loss: 0.94716\n",
      "  Epoch [40/50] - Loss: 0.93733\n",
      "  Epoch [50/50] - Loss: 0.92758\n",
      "  Accuracy: 0.00000\n",
      "  Validation MSE: 877.52667\n",
      "  R² Score: 0.01223\n",
      "Fold 4/5\n",
      "  Epoch [10/50] - Loss: 0.96843\n",
      "  Epoch [20/50] - Loss: 0.95325\n",
      "  Epoch [30/50] - Loss: 0.93911\n",
      "  Epoch [40/50] - Loss: 0.93082\n",
      "  Epoch [50/50] - Loss: 0.92301\n",
      "  Accuracy: 0.00000\n",
      "  Validation MSE: 893.65869\n",
      "  R² Score: 0.00277\n",
      "Fold 5/5\n",
      "  Epoch [10/50] - Loss: 0.96803\n",
      "  Epoch [20/50] - Loss: 0.95463\n",
      "  Epoch [30/50] - Loss: 0.94518\n",
      "  Epoch [40/50] - Loss: 0.93319\n",
      "  Epoch [50/50] - Loss: 0.92369\n",
      "  Accuracy: 0.00000\n",
      "  Validation MSE: 897.62805\n",
      "  R² Score: 0.00812\n",
      "Model saved to models/trained/NN.pkl\n"
     ]
    }
   ],
   "source": [
    "results = train_eval_save_NN(\n",
    "    data=data,\n",
    "    data_output=data_output,\n",
    "    scaler_y=scaler_y,\n",
    "    device=device,\n",
    "    k_folds=5,\n",
    "    num_epochs=50,\n",
    "    batch_size=64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Results:\n",
      "Fold 1: MSE = 894.61707, R² = 0.00986\n",
      "Fold 2: MSE = 910.96362, R² = -0.00085\n",
      "Fold 3: MSE = 877.52667, R² = 0.01223\n",
      "Fold 4: MSE = 893.65869, R² = 0.00277\n",
      "Fold 5: MSE = 897.62805, R² = 0.00812\n",
      "\n",
      "Average MSE: 894.87882\n",
      "Average R²: 0.00643\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCross-Validation Results:\")\n",
    "for res in results:\n",
    "    print(f\"Fold {res['fold']}: MSE = {res['mse']:.5f}, R² = {res['r2']:.5f}\")\n",
    "\n",
    "\n",
    "avg_mse = np.mean([r['mse'] for r in results])\n",
    "avg_r2 = np.mean([r['r2'] for r in results])\n",
    "print(f\"\\nAverage MSE: {avg_mse:.5f}\")\n",
    "print(f\"Average R²: {avg_r2:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
